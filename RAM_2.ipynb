{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import datetime as DT\n",
    "import time\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "def expand_columns(data):  pd.set_option('display.max_columns',len(data.columns))\n",
    "def describe2(data):\n",
    "    print(\"COUNT\", \"UNIQUE\", \"#_NULL\",\"DATA_TYPE\",\"COLUMN_NAME : FIRST ITEM\", sep=\"\\t\")\n",
    "    for column in data:\n",
    "        print(data[column].count(),data[column].nunique(),data[column].isnull().sum(), str(data[column].dtypes)+\"\\t\",str(column)+\" :\",data[column].iloc[0],sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Load Data #######\n",
    "data = pd.read_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\registrant_data.csv\", low_memory=False,encoding = \"ISO-8859-1\")\n",
    "data[\"Registrant ID\"] = data[\"Registrant ID\"].fillna(\"FILL_NULL_w_USER_ID:\"+data[\"User ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gender handling\n",
    "data[\"Gender\"] = data['Registrant Gender'].copy()\n",
    "data['Gender'] = data['Gender'].replace(to_replace=[\"Not specified\"], value=np.nan)\n",
    "data['Gender'] = data['Gender'].replace(to_replace=[\"f\",\"F\",'f ?'], value=\"Female\")\n",
    "data['Gender'] = data['Gender'].replace(to_replace=[\"m\",\"M\",'m?'], value=\"Male\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new registrant IDs\n",
    "# data = data.rename(columns = {'Registrant ID':\"Original Registrant ID\"})\n",
    "# data[\"Registrant ID\"] = data.groupby([\"Registrant First Name\",\"Registrant Last Name\", \"Registrant Birthdate\",\"Gender\"]).grouper.group_info[0].astype(str)\n",
    "# data[\"Registrant ID\"] =  np.where(data['Registrant ID'].str.contains(\"-\"),data[\"Original Registrant ID\"],data[\"Registrant ID\"])\n",
    "# data[\"Registrant ID\"] = data[\"Registrant ID\"].fillna(\"FILL_NULL_w_USER_ID:\"+data[\"User ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[\"Gender2\"] = data[\"Gender\"].copy()\n",
    "# data = pd.get_dummies(data, columns=[\"Gender2\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "# gb = data.copy()\n",
    "# gb = gb.groupby(\"Registrant ID\", as_index=False).mean()\n",
    "# gb = pd.merge(data,gb, how=\"left\", on=\"Registrant ID\")\n",
    "# gb.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\gb.csv\")\n",
    "\n",
    "# print(data[\"Original Registrant ID\"].nunique())\n",
    "# print(data[\"Registrant ID\"].nunique())\n",
    "# data[\"Registrant ID\"].nunique() - data[\"Original Registrant ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#format date variables\n",
    "#coerce date will drop dates not in proper format\n",
    "# .dt.date will convert back to date\n",
    "data[\"Registrant Birthdate\"] = pd.to_datetime(data[\"Registrant Birthdate\"],format='%Y-%m-%d',errors='coerce') \n",
    "data[\"event_date\"] = pd.to_datetime(data[\"event_date\"],format='%Y-%m-%d',errors='coerce')#.dt.date\n",
    "data[\"timestamp_registered\"] = pd.to_datetime(data[\"timestamp_registered\"],format='%Y-%m-%d',errors='coerce')\n",
    "data[\"Registration Date\"] = pd.to_datetime(data[\"timestamp_registered\"].copy().dt.date)\n",
    "data[\"Year\"]=(data[\"event_date\"].dt.year.astype(str)).str.replace('.0$', '').astype(float)\n",
    "\n",
    "#create minute result time variable as float\n",
    "data[\"result_time_Minutes\"] = pd.DatetimeIndex(data[\"result_time\"])\n",
    "data[\"result_time_Minutes\"] = data[\"result_time_Minutes\"].dt.hour *60 + data[\"result_time_Minutes\"].dt.minute +  data[\"result_time_Minutes\"].dt.second / 60\n",
    "\n",
    "#create minute result pace variable as float\n",
    "data[\"results_net_pace_Minutes\"] = pd.DatetimeIndex(data[\"results_net_pace\"])\n",
    "data[\"results_net_pace_Minutes\"] = data[\"results_net_pace_Minutes\"].dt.hour *60 + data[\"results_net_pace_Minutes\"].dt.minute +  data[\"results_net_pace_Minutes\"].dt.second / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    923756\n",
      "True       1436\n",
      "Name: Age at Event, dtype: int64\n",
      "False    924964\n",
      "True        228\n",
      "Name: Age at Event, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Age handling\n",
    "now = pd.Timestamp(DT.datetime.now())\n",
    "#create age variables\n",
    "data['Age'] = (now - data[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "data[\"Age at Event\"] = (data[\"event_date\"] - data[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "print((data[\"Age at Event\"] < 1).value_counts())\n",
    "print((data[\"Age at Event\"] > 80).value_counts())\n",
    "#remove birthdays less than 1 year or more than 80\n",
    "data['Age'] = np.where((data['Age'] < 1) | (data['Age'] > 80), np.nan, data[\"Age\"])\n",
    "data[\"Age at Event\"] = np.where((data['Age at Event'] < 1) | (data['Age at Event'] > 80), np.nan, data[\"Age at Event\"])\n",
    "\n",
    "# data[\"Registrant Birthdate\"] = data[\"Registrant Birthdate\"] #.dt.date #drop time so uploads into SAS as date, not datetime variable\n",
    "data[\"event_date\"] = pd.to_datetime(data[\"event_date\"]) #.dt.date\n",
    "# data[[\"Registrant Birthdate\",'Age',\"Age at Event\"]].describe(include=\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patrick.carey\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "C:\\Users\\patrick.carey\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "#Event categorization and Event distance/location handling\n",
    "\n",
    "#create dictionary of event dates\n",
    "cityEvent = data[[\"Registration Event Name\",\"event_date\"]].dropna()\n",
    "cityEvent = cityEvent.set_index(\"Registration Event Name\")[\"event_date\"].to_dict()\n",
    "data[\"event_date\"] = data[\"Registration Event Name\"].map(cityEvent) #fills in missing dates\n",
    "\n",
    "data[\"Registration Category\"] = data[\"Registration Category\"].str.upper().str.strip() #removes white spaces and capitalizes\n",
    "data[\"Kids\"] = data[\"Registration Category\"].str.extract(r'(YOUTH|JUNIOR|FAMILY|CHILD|KIDS)') #Kid or family marker\n",
    "data[\"Kids\"] = data[\"Kids\"].str.replace(r'(YOUTH|JUNIOR|FAMILY|CHILD|KIDS)', \"KIDS\") #for dummy variable later\n",
    "    #Catch 1.5 Mile Family Walk misclassified as 5 MILE\n",
    "data[\"Category\"] = data[\"Registration Category\"].str.extract(r'(15K|5K|10K|5 MILE|10 MILE|HALF MARATHON|SEASON PASS|DONATION|RAFFLE|CONCERT|KIDS RACE)')\n",
    "data[\"Category\"] = np.where(data['Registration Category'].str.contains(\"(AQUABIKE|DUATHLON|TRI|OLYMPIC|SPRINT|TEAM)\"),'TRI/OTHER',data[\"Category\"])\n",
    "data[\"Category\"] = np.where(data['Registration Category'].str.contains(\"TRIPLE NICKEL\"),\"TRIPLE NICKEL\",data[\"Category\"])\n",
    "data[\"Category\"] = np.where(data['Registration Event Name'].str.contains(\"Goodie Bag\"), \"GOODIE BAG\",data[\"Category\"])\n",
    "data[\"Category\"] = np.where(data['Registration Event Name'].str.contains(\"Training\"), \"TRAINING\",data[\"Category\"])\n",
    "data[\"Category\"] = np.where(data['Registration Event Name'].str.contains(\"(Bike Valet|Parking)\"), \"VALET/PARKING\",data[\"Category\"])\n",
    "data[\"Category\"] = np.where(data[\"Registration Category\"].str.contains(\"WALK\"), \"WALK\",data[\"Category\"])\n",
    "#extract new kids to categorical\n",
    "#location\n",
    "data[\"event_location\"] = np.where(data['Registration Event Name'].str.contains(\"Bangs Lake Multisport Festival\"), \"Wauconda, IL\",data[\"event_location\"])\n",
    "data[\"event_location\"] = np.where(data['Registration Event Name'].str.contains(\"2009 Terrapin 5K|Bucktown\"), \"Chicago, IL\",data[\"event_location\"])\n",
    "data[\"event_location\"] = np.where(data['Registration Event Name'].str.contains(\"North Shore\"), \"Highland Park, IL\",data[\"event_location\"])\n",
    "data[\"event_location\"] = np.where(data['Registration Event Name'].str.contains(\"Big Foot Triathlon\"), \"Lake Geneva, WI\",data[\"event_location\"])\n",
    "#distance\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"HALF MARATHON\"), 21,data[\"distance_qty\"])\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"5K\"), 5,data[\"distance_qty\"])\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"15K\"), 15,data[\"distance_qty\"])\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"10 MILE\"), 16,data[\"distance_qty\"])\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"5 MILE\"), 8,data[\"distance_qty\"])\n",
    "data[\"distance_qty\"] = np.where(data['Category'].str.contains(\"TRIPLE NICKEL\"), 13,data[\"distance_qty\"])\n",
    "data['distance_unit'] = \"kilometers\"\n",
    "\n",
    "data[\"Event\"] = data[\"Registration Event Name\"].str.upper().str.extract('(HOT CHOCOLATE|NORTH SHORE TURKEY TROT|CINCO DE MILER|BTN BIG 10K|FLEET FEET SPORTS SOLDIER FIELD 10 MILE|ROCK THE NIGHT 5K|BUCKTOWN 5K|HUMBOLDT PARK 5K|NORTH SHORE HALF MARATHON|BIG FOOT TRIATHLON|WALK FOR LITTLE CITY|TERRAPIN|TRAINING|BANGS LAKE MULTISPORT FESTIVAL|SOUTH SHORE TRIATHLON)')\n",
    "data[\"Event\"] = data[\"Event\"].fillna(\"MISCELLANEOUS\")\n",
    "\n",
    "data[\"event_date\"] = data[\"event_date\"].fillna(pd.to_datetime(data[\"timestamp_registered\"].dt.date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRI CAMP' 'THE PAMPERED RIDE (CHICAGO)' 'HITCHHIKE (CHICAGO)'\n",
      " 'THE PAMPERED RIDE (DEERFIELD)' \"WOMEN'S SPRINT\" \"WOMEN'S SPRINT - ATHENA\"\n",
      " 'DONATION' 'RAFFLE' '2014 5K SEASON PASS' '2014 DISTANCE SEASON PASS'\n",
      " '2015 SEASON PASS' 'TURKEY TROT' 'ROCK THE NIGHT' 'BUCKTOWN 5K SWAP'\n",
      " 'HOT CHOCOLATE 15K/5K HOODIE' 'BUCKTOWN 5K JACKET' '2016 SEASON PASS'\n",
      " 'LAS VEGAS 15K MEDAL' 'SEATTLE 15K MEDAL']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2011 RAM Tri Camp', '2011 Bike Valet Service',\n",
       "       '2011 She Bangs Tri', 'Help Mona Purdy', '2014 Season Pass',\n",
       "       '2015 Season Pass', 'Goodie Bag Mail Out', '2016 Season Pass',\n",
       "       'Extra Item: Mail Out'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[(data[\"Event\"]==\"MISCELLANEOUS\")][\"Registration Category\"].unique())\n",
    "data[(data[\"Event\"]==\"MISCELLANEOUS\")][\"Registration Event Name\"].unique()#[\"Registration Event Name\"].unique()#.str.contains(\"Goodie Bag\")][\"Registration Event Name\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geopy\n",
    "import geopy.distance\n",
    "locations = pd.read_table(\"C:\\\\Users\\\\patrick.carey\\\\Downloads\\\\US.txt\",encoding = \"ISO-8859-1\", low_memory=False, \n",
    "                          names=[\"country\",\"zip\",\"city\",\"full_state\",\"state\",\"county\", \"n\",\"n1\",\"n2\",\"latitude\",\"longitude\",\"n3\"])\n",
    "locations[\"zip\"] = locations[\"zip\"].astype(int).astype(str)\n",
    "locations['GPS'] = tuple(zip(locations.latitude, locations.longitude))\n",
    "locations['event_location'] = locations['city'] + ', ' + locations['state']\n",
    "GPS_City = locations.set_index('event_location')['GPS'].to_dict()\n",
    "GPS_City[\"St. Louis, MO\"] =(38.7023,-90.3644)\n",
    "GPS_City[\"Austin, Tx\"] =(30.3264,-97.7713)\n",
    "GPS_City[\"Washington DC\"] =(38.9122,-77.0177)\n",
    "GPS_Zip = locations.set_index('zip')['GPS'].to_dict()\n",
    "GPS_Lat = locations.set_index('zip')['latitude'].to_dict()\n",
    "GPS_Long = locations.set_index('zip')['longitude'].to_dict()\n",
    "data['city_coord'] = data['event_location'].map(GPS_City)\n",
    "data['zip_coord'] = data['Registrant Zipcode'].map(GPS_Zip)\n",
    "data['zip_coord_latitude'] = data['Registrant Zipcode'].map(GPS_Lat)\n",
    "data['zip_coord_longitude'] = data['Registrant Zipcode'].map(GPS_Long)\n",
    "\n",
    "data[\"Distance_To_Event(miles)\"] = data.apply(lambda x: geopy.distance.distance(x['city_coord'], x['zip_coord']).miles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago\n",
      "Atlanta\n",
      "Columbus\n",
      "Dallas\n",
      "Denver\n",
      "HighlandPark\n",
      "LakeGeneva\n",
      "Minneapolis\n",
      "Nashville\n",
      "Philadelphia\n",
      "Phoenix\n",
      "SanDiego\n",
      "SanFrancisco\n",
      "Seattle\n",
      "St.Louis\n"
     ]
    }
   ],
   "source": [
    "weather = pd.ExcelFile(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\2016-05-25_Weather.xlsx\")\n",
    "weatherDict ={}\n",
    "for tab in weather.sheet_names:\n",
    "    print(tab.replace(\" \",\"*\").replace(\"*\",\"\").partition(\",\")[0])\n",
    "    #add each excel tab to the dictionary with name printed\n",
    "    weatherDict[tab.replace(\" \",\"\").replace(\".\",\"\").partition(\",\")[0]]=pd.DataFrame(weather.parse(tab))\n",
    "    #add location column\n",
    "#     weatherDict[tab.replace(\" \",\"\").replace(\".\",\"\").partition(\",\")[0]].insert(0, \"Location\", tab)\n",
    "    #add 30 day rolling average of temperature\n",
    "    weatherDict[tab.replace(\" \",\"\").replace(\".\",\"\").partition(\",\")[0]][\"Prev_30d_Mean_Temp\"] = pd.rolling_mean(weatherDict[tab.replace(\" \",\"\").replace(\".\",\"\").partition(\",\")[0]][\"Mean TemperatureF\"], window=30)\n",
    "    \n",
    "\n",
    "# data[\"event_location\"].unique() #list of all cities, weather only includes events with more than one year of race data\n",
    "\n",
    "#move all weather data into one dataframe for merging\n",
    "weather = pd.DataFrame(columns=weatherDict[\"Chicago\"].keys())\n",
    "# weather = pd.DataFrame(weatherDict[\"Chicago\"].keys())\n",
    "for dic in weatherDict:\n",
    "    temp = pd.DataFrame.from_dict(weatherDict[dic])\n",
    "    weather = pd.concat([weather,temp])\n",
    "\n",
    "#clean column headers\n",
    "weather = weather.rename(columns = {'Date':\"Registration Date\", 'Location': 'event_location','Mean TemperatureF':\"Registration Day TemperatureF\",'Prev_30d_Mean_Temp':'Registration Day Prev_30d_Mean_Temp'})\n",
    "weather = weather.rename(columns=lambda x: x.strip())\n",
    "weather = weather[[\"Registration Date\",'event_location', 'Registration Day TemperatureF', 'Registration Day Prev_30d_Mean_Temp']]\n",
    "#get weather of date registered\n",
    "# data[\"Registration Date\"] = data[\"event_date\"] - pd.to_timedelta(data[\"days_out_registered\"],unit='d')\n",
    "data = pd.merge(data, weather, how='left')\n",
    "\n",
    "#clean column headers\n",
    "weather = weather.rename(columns = {'Registration Date':'event_date', \"Registration Day TemperatureF\": 'Mean TemperatureF','Registration Day Prev_30d_Mean_Temp':'Prev_30d_Mean_Temp'})\n",
    "weather = weather.rename(columns=lambda x: x.strip())\n",
    "weather = weather[[\"event_date\",'event_location', 'Mean TemperatureF', 'Prev_30d_Mean_Temp']]\n",
    "#merge to take only relevant dates\n",
    "weather = pd.merge(data[[\"Event\",\"event_date\",'event_location']].copy(), weather, how='left', on=[\"event_date\",'event_location']).drop_duplicates().sort_values(by=[\"Event\",\"event_location\",\"event_date\"])\n",
    "\n",
    "# g = weather[['Event','event_location',\"event_date\", 'Mean TemperatureF', 'Prev_30d_Mean_Temp']].drop_duplicates().sort_values(by=[\"Event\",\"event_location\",\"event_date\"])\n",
    "g = weather.copy().groupby([\"Event\",\"event_location\"])\n",
    "weather['Previous Year Mean TemperatureF'] = g['Mean TemperatureF'].apply(lambda x: x.shift())\n",
    "weather['Previous Year 30d_Mean_Temp'] = g['Prev_30d_Mean_Temp'].apply(lambda x: x.shift())\n",
    "\n",
    "weather = weather.reset_index()\n",
    "data = pd.merge(data, weather, how='left')\n",
    "data = data.drop(\"index\",1)\n",
    "\n",
    "# data[\"Registration Day/30d Temperature\"] = data[\"Registration Day TemperatureF\"] / data['Registration Day Prev_30d_Mean_Temp']\n",
    "# data['Event Mean Temperature/Previous Year'] = data[\"Mean TemperatureF\"] / data[\"Previous Year Mean TemperatureF\"]\n",
    "# data['Event Rolling 30d_Mean_Temp/Previous Year'] = data[\"Prev_30d_Mean_Temp\"] / data[\"Previous Year 30d_Mean_Temp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>User Email</th>\n",
       "      <th>User First Name</th>\n",
       "      <th>User Last Name</th>\n",
       "      <th>Registrant ID</th>\n",
       "      <th>Registrant Email</th>\n",
       "      <th>Count</th>\n",
       "      <th>Registrant First Name</th>\n",
       "      <th>Registrant Last Name</th>\n",
       "      <th>Registrant Gender</th>\n",
       "      <th>Registrant Birthdate</th>\n",
       "      <th>Registrant Zipcode</th>\n",
       "      <th>Registration ID</th>\n",
       "      <th>Registration Event Name</th>\n",
       "      <th>Registration Category</th>\n",
       "      <th>distance_qty</th>\n",
       "      <th>distance_unit</th>\n",
       "      <th>event_location</th>\n",
       "      <th>event_date</th>\n",
       "      <th>fees_event</th>\n",
       "      <th>fundraising</th>\n",
       "      <th>fundraising_goal</th>\n",
       "      <th>days_out_registered</th>\n",
       "      <th>timestamp_registered</th>\n",
       "      <th>result_time</th>\n",
       "      <th>results_net_pace</th>\n",
       "      <th>fees_first</th>\n",
       "      <th>fees_first_until</th>\n",
       "      <th>fees_second</th>\n",
       "      <th>fees_second_until</th>\n",
       "      <th>fees_third</th>\n",
       "      <th>fees_third_until</th>\n",
       "      <th>fees_fourth</th>\n",
       "      <th>fees_fourth_until</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Registration Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>result_time_Minutes</th>\n",
       "      <th>results_net_pace_Minutes</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age at Event</th>\n",
       "      <th>Kids</th>\n",
       "      <th>Category</th>\n",
       "      <th>Event</th>\n",
       "      <th>city_coord</th>\n",
       "      <th>zip_coord</th>\n",
       "      <th>zip_coord_latitude</th>\n",
       "      <th>zip_coord_longitude</th>\n",
       "      <th>Distance_To_Event(miles)</th>\n",
       "      <th>Registration Day TemperatureF</th>\n",
       "      <th>Registration Day Prev_30d_Mean_Temp</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "      <th>Prev_30d_Mean_Temp</th>\n",
       "      <th>Previous Year Mean TemperatureF</th>\n",
       "      <th>Previous Year 30d_Mean_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4d8aaf97-16e4-4b23-b421-0c4f7f000001</td>\n",
       "      <td>deannagill@comcast.net</td>\n",
       "      <td>Dede</td>\n",
       "      <td>Gill</td>\n",
       "      <td>4d8aaf97-9098-4707-b672-0c4f7f000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>Dede</td>\n",
       "      <td>Gill</td>\n",
       "      <td>Female</td>\n",
       "      <td>1975-01-19</td>\n",
       "      <td>60050</td>\n",
       "      <td>4d8aaf97-f208-42f8-9300-0c4f7f000001</td>\n",
       "      <td>2011 Hot Chocolate 15K/5K - Chicago</td>\n",
       "      <td>15K</td>\n",
       "      <td>15</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>2011-02-28 11:20:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15K</td>\n",
       "      <td>HOT CHOCOLATE</td>\n",
       "      <td>(41.8119, -87.6873)</td>\n",
       "      <td>(42.3311, -88.2955)</td>\n",
       "      <td>42.3311</td>\n",
       "      <td>-88.2955</td>\n",
       "      <td>47.563132</td>\n",
       "      <td>32</td>\n",
       "      <td>27.733333</td>\n",
       "      <td>47</td>\n",
       "      <td>53.9</td>\n",
       "      <td>36</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4d8aaf9b-9f08-4e10-94c9-0c4f7f000001</td>\n",
       "      <td>rswee@comcast.net</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Swee</td>\n",
       "      <td>4d8aaf9b-2668-463b-aeb8-0c4f7f000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Swee</td>\n",
       "      <td>Male</td>\n",
       "      <td>1954-03-27</td>\n",
       "      <td>60044</td>\n",
       "      <td>4d8aaf9b-bec0-46c8-b0a5-0c4f7f000001</td>\n",
       "      <td>2011 Hot Chocolate 15K/5K - Chicago</td>\n",
       "      <td>15K</td>\n",
       "      <td>15</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>2011-02-14 20:50:30</td>\n",
       "      <td>01:11:03</td>\n",
       "      <td>00:07:38</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "      <td>71.050000</td>\n",
       "      <td>7.633333</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15K</td>\n",
       "      <td>HOT CHOCOLATE</td>\n",
       "      <td>(41.8119, -87.6873)</td>\n",
       "      <td>(42.282, -87.856)</td>\n",
       "      <td>42.2820</td>\n",
       "      <td>-87.8560</td>\n",
       "      <td>33.586086</td>\n",
       "      <td>37</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>47</td>\n",
       "      <td>53.9</td>\n",
       "      <td>36</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4d8aaf9e-ee50-47bf-87ad-0c4f7f000001</td>\n",
       "      <td>tom@gamainc.com</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Golbeck</td>\n",
       "      <td>4d8aaf9e-5a10-4ff6-ba0b-0c4f7f000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Golbeck</td>\n",
       "      <td>Male</td>\n",
       "      <td>1979-04-03</td>\n",
       "      <td>60012</td>\n",
       "      <td>4d8aaf9e-1a28-4865-ab37-0c4f7f000001</td>\n",
       "      <td>2011 Hot Chocolate 15K/5K - Chicago</td>\n",
       "      <td>15K</td>\n",
       "      <td>15</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>2011-02-14 09:54:49</td>\n",
       "      <td>01:18:42</td>\n",
       "      <td>00:08:27</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "      <td>78.700000</td>\n",
       "      <td>8.450000</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15K</td>\n",
       "      <td>HOT CHOCOLATE</td>\n",
       "      <td>(41.8119, -87.6873)</td>\n",
       "      <td>(42.2662, -88.3213)</td>\n",
       "      <td>42.2662</td>\n",
       "      <td>-88.3213</td>\n",
       "      <td>45.245022</td>\n",
       "      <td>37</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>47</td>\n",
       "      <td>53.9</td>\n",
       "      <td>36</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4d8aafa9-11a0-4b2a-8f1d-0c4f7f000001</td>\n",
       "      <td>jorays@comcast.net</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Joray</td>\n",
       "      <td>4d8aafa9-adb4-48db-af1a-0c4f7f000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Joray</td>\n",
       "      <td>Female</td>\n",
       "      <td>1971-01-15</td>\n",
       "      <td>60046</td>\n",
       "      <td>4d8aafa9-5ea0-4ceb-ab09-0c4f7f000001</td>\n",
       "      <td>2011 Hot Chocolate 15K/5K - Chicago</td>\n",
       "      <td>15K</td>\n",
       "      <td>15</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>2011-02-14 14:06:32</td>\n",
       "      <td>01:22:40</td>\n",
       "      <td>00:08:53</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>8.883333</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15K</td>\n",
       "      <td>HOT CHOCOLATE</td>\n",
       "      <td>(41.8119, -87.6873)</td>\n",
       "      <td>(42.3813, -87.9991)</td>\n",
       "      <td>42.3813</td>\n",
       "      <td>-87.9991</td>\n",
       "      <td>42.441880</td>\n",
       "      <td>37</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>47</td>\n",
       "      <td>53.9</td>\n",
       "      <td>36</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4d8aafa9-d200-4997-8386-0c4f7f000001</td>\n",
       "      <td>JAMESREYNOLDSC@AOL.COM</td>\n",
       "      <td>James</td>\n",
       "      <td>Reynolds</td>\n",
       "      <td>4d8aafa9-7d50-4698-ace2-0c4f7f000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>James</td>\n",
       "      <td>Reynolds</td>\n",
       "      <td>Male</td>\n",
       "      <td>1945-09-03</td>\n",
       "      <td>60618</td>\n",
       "      <td>4d8aafaa-1a58-4726-9592-0c4f7f000001</td>\n",
       "      <td>2011 Hot Chocolate 15K/5K - Chicago</td>\n",
       "      <td>15K</td>\n",
       "      <td>15</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>2011-03-03 11:25:01</td>\n",
       "      <td>01:41:43</td>\n",
       "      <td>00:10:55</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>2011</td>\n",
       "      <td>101.716667</td>\n",
       "      <td>10.916667</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15K</td>\n",
       "      <td>HOT CHOCOLATE</td>\n",
       "      <td>(41.8119, -87.6873)</td>\n",
       "      <td>(41.9464, -87.7042)</td>\n",
       "      <td>41.9464</td>\n",
       "      <td>-87.7042</td>\n",
       "      <td>9.323526</td>\n",
       "      <td>36</td>\n",
       "      <td>28.633333</td>\n",
       "      <td>47</td>\n",
       "      <td>53.9</td>\n",
       "      <td>36</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                User ID              User Email  \\\n",
       "0  4d8aaf97-16e4-4b23-b421-0c4f7f000001  deannagill@comcast.net   \n",
       "1  4d8aaf9b-9f08-4e10-94c9-0c4f7f000001       rswee@comcast.net   \n",
       "2  4d8aaf9e-ee50-47bf-87ad-0c4f7f000001         tom@gamainc.com   \n",
       "3  4d8aafa9-11a0-4b2a-8f1d-0c4f7f000001      jorays@comcast.net   \n",
       "4  4d8aafa9-d200-4997-8386-0c4f7f000001  JAMESREYNOLDSC@AOL.COM   \n",
       "\n",
       "  User First Name User Last Name                         Registrant ID  \\\n",
       "0            Dede           Gill  4d8aaf97-9098-4707-b672-0c4f7f000001   \n",
       "1          Robert           Swee  4d8aaf9b-2668-463b-aeb8-0c4f7f000001   \n",
       "2             Tom        Golbeck  4d8aaf9e-5a10-4ff6-ba0b-0c4f7f000001   \n",
       "3         Rebecca          Joray  4d8aafa9-adb4-48db-af1a-0c4f7f000001   \n",
       "4           James       Reynolds  4d8aafa9-7d50-4698-ace2-0c4f7f000001   \n",
       "\n",
       "  Registrant Email  Count Registrant First Name Registrant Last Name  \\\n",
       "0              NaN      8                  Dede                 Gill   \n",
       "1              NaN     15                Robert                 Swee   \n",
       "2              NaN      2                   Tom              Golbeck   \n",
       "3              NaN      5               Rebecca                Joray   \n",
       "4              NaN     23                 James             Reynolds   \n",
       "\n",
       "  Registrant Gender Registrant Birthdate Registrant Zipcode  \\\n",
       "0            Female           1975-01-19              60050   \n",
       "1              Male           1954-03-27              60044   \n",
       "2              Male           1979-04-03              60012   \n",
       "3            Female           1971-01-15              60046   \n",
       "4              Male           1945-09-03              60618   \n",
       "\n",
       "                        Registration ID              Registration Event Name  \\\n",
       "0  4d8aaf97-f208-42f8-9300-0c4f7f000001  2011 Hot Chocolate 15K/5K - Chicago   \n",
       "1  4d8aaf9b-bec0-46c8-b0a5-0c4f7f000001  2011 Hot Chocolate 15K/5K - Chicago   \n",
       "2  4d8aaf9e-1a28-4865-ab37-0c4f7f000001  2011 Hot Chocolate 15K/5K - Chicago   \n",
       "3  4d8aafa9-5ea0-4ceb-ab09-0c4f7f000001  2011 Hot Chocolate 15K/5K - Chicago   \n",
       "4  4d8aafaa-1a58-4726-9592-0c4f7f000001  2011 Hot Chocolate 15K/5K - Chicago   \n",
       "\n",
       "  Registration Category  distance_qty distance_unit event_location event_date  \\\n",
       "0                   15K            15    kilometers    Chicago, IL 2011-11-05   \n",
       "1                   15K            15    kilometers    Chicago, IL 2011-11-05   \n",
       "2                   15K            15    kilometers    Chicago, IL 2011-11-05   \n",
       "3                   15K            15    kilometers    Chicago, IL 2011-11-05   \n",
       "4                   15K            15    kilometers    Chicago, IL 2011-11-05   \n",
       "\n",
       "   fees_event  fundraising  fundraising_goal  days_out_registered  \\\n",
       "0          65            0                 0                  249   \n",
       "1          65            0                 0                  263   \n",
       "2          65            0                 0                  263   \n",
       "3          65            0                 0                  263   \n",
       "4          65            0                 0                  246   \n",
       "\n",
       "  timestamp_registered result_time results_net_pace  fees_first  \\\n",
       "0  2011-02-28 11:20:07         NaN              NaN          65   \n",
       "1  2011-02-14 20:50:30    01:11:03         00:07:38          65   \n",
       "2  2011-02-14 09:54:49    01:18:42         00:08:27          65   \n",
       "3  2011-02-14 14:06:32    01:22:40         00:08:53          65   \n",
       "4  2011-03-03 11:25:01    01:41:43         00:10:55          65   \n",
       "\n",
       "  fees_first_until  fees_second fees_second_until  fees_third  \\\n",
       "0              NaN          NaN               NaN         NaN   \n",
       "1              NaN          NaN               NaN         NaN   \n",
       "2              NaN          NaN               NaN         NaN   \n",
       "3              NaN          NaN               NaN         NaN   \n",
       "4              NaN          NaN               NaN         NaN   \n",
       "\n",
       "  fees_third_until  fees_fourth fees_fourth_until  Gender Registration Date  \\\n",
       "0              NaN          NaN               NaN  Female        2011-02-28   \n",
       "1              NaN          NaN               NaN    Male        2011-02-14   \n",
       "2              NaN          NaN               NaN    Male        2011-02-14   \n",
       "3              NaN          NaN               NaN  Female        2011-02-14   \n",
       "4              NaN          NaN               NaN    Male        2011-03-03   \n",
       "\n",
       "   Year  result_time_Minutes  results_net_pace_Minutes  Age  Age at Event  \\\n",
       "0  2011                  NaN                       NaN   41            36   \n",
       "1  2011            71.050000                  7.633333   62            57   \n",
       "2  2011            78.700000                  8.450000   37            32   \n",
       "3  2011            82.666667                  8.883333   45            40   \n",
       "4  2011           101.716667                 10.916667   70            66   \n",
       "\n",
       "  Kids Category          Event           city_coord            zip_coord  \\\n",
       "0  NaN      15K  HOT CHOCOLATE  (41.8119, -87.6873)  (42.3311, -88.2955)   \n",
       "1  NaN      15K  HOT CHOCOLATE  (41.8119, -87.6873)    (42.282, -87.856)   \n",
       "2  NaN      15K  HOT CHOCOLATE  (41.8119, -87.6873)  (42.2662, -88.3213)   \n",
       "3  NaN      15K  HOT CHOCOLATE  (41.8119, -87.6873)  (42.3813, -87.9991)   \n",
       "4  NaN      15K  HOT CHOCOLATE  (41.8119, -87.6873)  (41.9464, -87.7042)   \n",
       "\n",
       "   zip_coord_latitude  zip_coord_longitude  Distance_To_Event(miles)  \\\n",
       "0             42.3311             -88.2955                 47.563132   \n",
       "1             42.2820             -87.8560                 33.586086   \n",
       "2             42.2662             -88.3213                 45.245022   \n",
       "3             42.3813             -87.9991                 42.441880   \n",
       "4             41.9464             -87.7042                  9.323526   \n",
       "\n",
       "   Registration Day TemperatureF  Registration Day Prev_30d_Mean_Temp  \\\n",
       "0                             32                            27.733333   \n",
       "1                             37                            21.166667   \n",
       "2                             37                            21.166667   \n",
       "3                             37                            21.166667   \n",
       "4                             36                            28.633333   \n",
       "\n",
       "   Mean TemperatureF  Prev_30d_Mean_Temp  Previous Year Mean TemperatureF  \\\n",
       "0                 47                53.9                               36   \n",
       "1                 47                53.9                               36   \n",
       "2                 47                53.9                               36   \n",
       "3                 47                53.9                               36   \n",
       "4                 47                53.9                               36   \n",
       "\n",
       "   Previous Year 30d_Mean_Temp  \n",
       "0                         53.8  \n",
       "1                         53.8  \n",
       "2                         53.8  \n",
       "3                         53.8  \n",
       "4                         53.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_columns(data)\n",
    "data.head()\n",
    "# # data.columns\n",
    "# # data[data[\"Registration Day/30d Temperature\"] > 3]\n",
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\2016-06-07 registrant_data_Processed.csv\", index=False)\n",
    "#########Finished preprocessing transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#number of duplicates #some duplicates have one variable different such as net pace NaN\n",
    "expand_columns(data)\n",
    "# data.describe(include=\"all\")\n",
    "print(data.duplicated(subset=[\"Original Registrant ID\", \"Registration Event Name\", \"Registration Category\"], keep=False).sum())\n",
    "print(data.duplicated(subset=[\"Original Registrant ID\", \"Registration Event Name\", \"Registration Category\"]).sum())\n",
    "\n",
    "print(data.duplicated(subset=[\"Registrant ID\", \"Registration Event Name\", \"Registration Category\"], keep=False).sum())\n",
    "print(data.duplicated(subset=[\"Registrant ID\", \"Registration Event Name\", \"Registration Category\"]).sum())\n",
    "\n",
    "print(data.duplicated(subset=[\"Original Registrant ID\",\"Registrant ID\", \"Registration Event Name\", \"Registration Category\"], keep=False).sum())\n",
    "print(data.duplicated(subset=[\"Original Registrant ID\",\"Registrant ID\", \"Registration Event Name\", \"Registration Category\"]).sum())\n",
    "\n",
    "data[data.duplicated(subset=[\"Original Registrant ID\",\"Registrant ID\", \"Registration Event Name\", \"Registration Category\"], keep=False)].sort_values(\"Original Registrant ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "data[data[\"fees_event\"]<1][\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[(data[\"fees_event\"]<1) & (data[\"Category\"]==\"15K\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some registrants have a total negative fees\n",
    "data[data[\"Original Registrant ID\"] == \"4d8ab892-a1e0-440b-a353-0c4f7f000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Begin Creation of analytics dataframe #\n",
    "#########################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import datetime as DT\n",
    "def lastValue(x):\n",
    "    #lambda x: x.dropna().iloc[-1]\n",
    "    try:\n",
    "        return x.dropna().iloc[-1]\n",
    "    except:\n",
    "        return x.iloc[-1]\n",
    "def expand_columns(data):  pd.set_option('display.max_columns',len(data.columns))\n",
    "def describe2(data):\n",
    "    print(\"COUNT\", \"UNIQUE\", \"#_NULL\",\"DATA_TYPE\",\"COLUMN_NAME : FIRST ITEM\", sep=\"\\t\")\n",
    "    for column in data:\n",
    "        print(data[column].count(),data[column].nunique(),data[column].isnull().sum(), str(data[column].dtypes)+\"\\t\",str(column)+\" :\",data[column].iloc[0],sep=\"\\t\")\n",
    "data = pd.read_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\2016-06-07 registrant_data_Processed.csv\", low_memory=False,encoding = \"ISO-8859-1\")\n",
    "data[\"Registrant Birthdate\"] = pd.to_datetime(data[\"Registrant Birthdate\"],format='%Y-%m-%d')#,errors='coerce') \n",
    "data[\"event_date\"] = pd.to_datetime(data[\"event_date\"],format='%Y-%m-%d')#,errors='coerce')#.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\registrant_data\\registrant_data.csv\", low_memory=False,encoding = \"ISO-8859-1\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data[\"Event\"] = data[\"Registration Event Name\"].str.upper().str.extract('(HOT CHOCOLATE)')\n",
    "# data[\"Year\"] = pd.to_datetime(data[\"event_date\"]).dt.year\n",
    "# data[\"Registrant ID\"] = data[\"Registrant ID\"].fillna(\"FILL_NULL_w_USER_ID:\"+data[\"User ID\"])\n",
    "# HC_2009 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2009) & (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2010 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2010)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2011 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2011)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2012 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2012)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2013 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2013)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2014 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2014)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n",
    "# HC_2015 = data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2015)& (data[\"event_location\"]==\"Chicago, IL\")][\"Registrant ID\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp1 = ['One', 'Two', 'Three', 'Four']\n",
    "# temp2 = ['One', 'Two','five']\n",
    "# temp3 = list(set(temp1) - set(temp2))\n",
    "# temp3\n",
    "\n",
    "# temp15 = list(set(HC_2015) - set(HC_2013)-set(HC_2012) - set(HC_2011)-set(HC_2010) - set(HC_2009))\n",
    "# temp14 = list(set(HC_2014) - set(HC_2013)-set(HC_2012) - set(HC_2011)-set(HC_2010) - set(HC_2009))\n",
    "# data[(data[\"Event\"]==\"HOT CHOCOLATE\") & (data[\"Year\"]==2014)][\"Registrant ID\"].isin(temp15).sum()\n",
    "# list(set(HC_2014) - set(temp15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[\"Event\"] = data[\"Registration Event Name\"].str.upper().str.extract('(HOT CHOCOLATE)')\n",
    "# (data[\"Event\"]==\"HOT CHOCOLATE\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[\"Event\"] = data[\"Registration Event Name\"].str.upper().str.extract('(HOT CHOCOLATE)')\n",
    "# data[\"Registration Event Name\"]=data[\"Registration Event Name\"].str.upper()\n",
    "# data[\"?\"] = data[\"Registration Event Name\"].str.contains('HOT CHOCOLATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[\"?\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#recreate GPS after loading processed data\n",
    "import geopy\n",
    "import geopy.distance\n",
    "locations = pd.read_table(\"C:\\\\Users\\\\patrick.carey\\\\Downloads\\\\US.txt\",encoding = \"ISO-8859-1\", low_memory=False, \n",
    "                          names=[\"country\",\"zip\",\"city\",\"full_state\",\"state\",\"county\", \"n\",\"n1\",\"n2\",\"latitude\",\"longitude\",\"n3\"])\n",
    "locations[\"zip\"] = locations[\"zip\"].astype(int).astype(str)\n",
    "locations['GPS'] = tuple(zip(locations.latitude, locations.longitude))\n",
    "locations['event_location'] = locations['city'] + ', ' + locations['state']\n",
    "GPS_City = locations.set_index('event_location')['GPS'].to_dict()\n",
    "GPS_Zip = locations.set_index('zip')['GPS'].to_dict()\n",
    "GPS_Lat = locations.set_index('zip')['latitude'].to_dict()\n",
    "GPS_Long = locations.set_index('zip')['longitude'].to_dict()\n",
    "# data['city_coord'] = data['event_location'].map(GPS_City)\n",
    "# data['zip_coord'] = data['Registrant Zipcode'].map(GPS_Zip)\n",
    "# data['zip_coord_latitude'] = data['Registrant Zipcode'].map(GPS_Lat)\n",
    "# data['zip_coord_longitude'] = data['Registrant Zipcode'].map(GPS_Long)\n",
    "# data[\"Distance_To_Event(miles)\"] = data.apply(lambda x: geopy.distance.distance(x['city_coord'], x['zip_coord']).miles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data[\"Event\"]==\"HOT CHOCOLATE\"][\"event_location\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "# data.head()\n",
    "# data.describe()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clist = ['Chicago, IL', 'Dallas, TX', 'San Diego, CA','Atlanta, GA', 'Seattle, WA', 'Columbus, OH',\n",
    "         'Minneapolis, MN','Philadelphia, PA', 'San Francisco, CA', 'St. Louis, MO','Nashville, TN', 'Denver, CO']\n",
    "# clist = ['Chicago, IL']\n",
    "for c in clist: \n",
    "    try:\n",
    "        #DataFrame to predict\n",
    "\n",
    "        year = 2015 \n",
    "        city = c\n",
    "#         city = \"Chicago, IL\" \n",
    "        race = \"HOT CHOCOLATE\" \n",
    "        category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "        regId_city = data[(data[\"event_location\"]==city)][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "        # filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "        #        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "        #        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "        #        'KIDS RACE', '10 MILE']\n",
    "        date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "        if category == None: \n",
    "            dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"] \n",
    "            fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\" + city + \"_\" + str(year) + \".csv\"\n",
    "        else: \n",
    "            dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "            fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "        # # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "        # df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "        # df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "        #df of previous registrants that attended event in city\n",
    "        df = data[(data[\"event_date\"] < date) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "        print(df[\"Registrant ID\"].nunique())\n",
    "        df = df.drop(\"Count\", 1)\n",
    "        df[\"Age at Event\"] = (pd.to_datetime(date) - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "        df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "        df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "        df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "        df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "        df['HOT CHOCOLATE'] = np.where(df['Event'].str.contains(\"HOT CHOCOLATE\"), 1,0)\n",
    "        dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "        df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "        df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "        df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "        df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "        gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                                      'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                                      'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, \n",
    "                                                      'Event Rolling 30d_Mean_Temp/Previous Year': np.mean,'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                                      '5 MILE': np.sum, '5K': np.sum, 'HOT CHOCOLATE': np.sum, dependent_variable: np.max})\n",
    "\n",
    "        gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "        def change_column_order(df, col_name, index):\n",
    "            cols = df.columns.tolist()\n",
    "            cols.remove(col_name)\n",
    "            cols.insert(index, col_name)\n",
    "            return df[cols]\n",
    "#         gId = pd.concat([gId, gId2], axis=1)\n",
    "        gId = gId.drop(\"Male\", 1)\n",
    "        gId = pd.DataFrame(gId)\n",
    "        gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "        gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "        gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "        gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "        # zscore = lambda x: (x - x.mean()) / x.std()\n",
    "        # g = gId[:-1].apply(zscore)\n",
    "        print(len(gId))\n",
    "        gId.to_csv(fileName)\n",
    "    except:\n",
    "        print(\"pass \" + city)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clist = ['Chicago, IL', 'Dallas, TX', 'San Diego, CA','Atlanta, GA', 'Seattle, WA', 'Columbus, OH',\n",
    "#          'Minneapolis, MN','Philadelphia, PA', 'San Francisco, CA', 'St. Louis, MO','Nashville, TN', 'Denver, CO']\n",
    "clist = ['Chicago, IL']\n",
    "\n",
    "#DataFrame to predict\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "regId_city = data[(data[\"event_location\"]==city)][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\" + city + \"_\" + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"event_date\"] < date) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(date) - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, \n",
    "                                              'Event Rolling 30d_Mean_Temp/Previous Year': np.mean,'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                              '5 MILE': np.sum, '5K': np.sum, dependent_variable: np.max})\n",
    "\n",
    "gId23 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "# gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns\n",
    "data[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671414\n",
      "649407\n",
      "671414\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#DataFrame to registrant ID\n",
    "date = pd.to_datetime('3/11/2016') #date recieved files\n",
    "df = data[(data[\"event_date\"] < date)].copy().sort_values(by=\"event_date\")\n",
    "# df = data.copy().sort_values(by=\"event_date\")\n",
    "print(data[\"Registrant ID\"].nunique())\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "# gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.mean,\"Age\": np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "#                                               'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "#                                               'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "#                                               'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "#                                               'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),\n",
    "#                                               'Female': np.max, 'Male': np.max, '10K': np.max,'15K': np.max, '5 MILE': np.max, '5K': np.max, \n",
    "#                                               \"zip_coord_latitude\": np.mean, \"zip_coord_longitude\": np.mean, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").mean()\n",
    "gId2 = pd.get_dummies(data.copy()[[\"Registrant ID\",\"Registration Category\",\"Category\",\"Kids\",\"Event\"]], columns = [\"Category\",\"Kids\",\"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "gId2['5 MILE'] = np.where(gId2['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,gId2['5 MILE']) \n",
    "gId2['5K'] = np.where(gId2['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,gId2['5K'])\n",
    "gId2 = gId2.groupby(\"Registrant ID\").sum()\n",
    "gId2 = gId2.drop(\"TRAINING\",1)\n",
    "\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "#balance data\n",
    "# gId = gId.dropna()\n",
    "# y = gId[gId[dependent_variable.title()] ==1].copy()\n",
    "# n = gId[gId[dependent_variable.title()] ==0].copy().sample(n=(len(y.index)))\n",
    "# yn = pd.concat([y, n], axis=0)\n",
    "# yn.to_csv(fileName)\n",
    "# print(len(yn))\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "\n",
    "print(len(gId))\n",
    "gId.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\Ram_Registrants.csv\")\n",
    "#fill na with mean\n",
    "gId= gId.fillna(gId.mean())\n",
    "gId.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\Ram_RegistrantsMean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10 Mile</th>\n",
       "      <th>10K</th>\n",
       "      <th>15K</th>\n",
       "      <th>5 Mile</th>\n",
       "      <th>5K</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age At Event</th>\n",
       "      <th>Bangs Lake Multisport Festival</th>\n",
       "      <th>Big Foot Triathlon</th>\n",
       "      <th>Btn Big 10K</th>\n",
       "      <th>Bucktown 5K</th>\n",
       "      <th>Cinco De Miler</th>\n",
       "      <th>Concert</th>\n",
       "      <th>Days_Out_Registered</th>\n",
       "      <th>Distance_To_Event(Miles)</th>\n",
       "      <th>Donation</th>\n",
       "      <th>Fees_Event</th>\n",
       "      <th>Female</th>\n",
       "      <th>Fleet Feet Sports Soldier Field 10 Mile</th>\n",
       "      <th>Fundraising</th>\n",
       "      <th>Fundraising_Goal</th>\n",
       "      <th>Goodie Bag</th>\n",
       "      <th>Half Marathon</th>\n",
       "      <th>Hot Chocolate</th>\n",
       "      <th>Humboldt Park 5K</th>\n",
       "      <th>Kids</th>\n",
       "      <th>Kids Race</th>\n",
       "      <th>Male</th>\n",
       "      <th>Mean Temperaturef</th>\n",
       "      <th>Miscellaneous</th>\n",
       "      <th>North Shore Half Marathon</th>\n",
       "      <th>North Shore Turkey Trot</th>\n",
       "      <th>Prev_30D_Mean_Temp</th>\n",
       "      <th>Previous Year 30D_Mean_Temp</th>\n",
       "      <th>Previous Year Mean Temperaturef</th>\n",
       "      <th>Raffle</th>\n",
       "      <th>Registration Day Prev_30D_Mean_Temp</th>\n",
       "      <th>Registration Day Temperaturef</th>\n",
       "      <th>Result_Time_Minutes</th>\n",
       "      <th>Results_Net_Pace_Minutes</th>\n",
       "      <th>Rock The Night 5K</th>\n",
       "      <th>Season Pass</th>\n",
       "      <th>South Shore Triathlon</th>\n",
       "      <th>Terrapin</th>\n",
       "      <th>Tri/Other</th>\n",
       "      <th>Triple Nickel</th>\n",
       "      <th>Valet/Parking</th>\n",
       "      <th>Walk</th>\n",
       "      <th>Walk For Little City</th>\n",
       "      <th>Year</th>\n",
       "      <th>Zip_Coord_Latitude</th>\n",
       "      <th>Zip_Coord_Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4d8aaf92-1770-468a-8c81-0c4f7f000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>51.964078</td>\n",
       "      <td>0</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.916667</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>75.616667</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.666667</td>\n",
       "      <td>41.4706</td>\n",
       "      <td>-87.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d8aaf92-17a0-42f6-9855-0c4f7f000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.025178</td>\n",
       "      <td>0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.833333</td>\n",
       "      <td>51.052010</td>\n",
       "      <td>48.104333</td>\n",
       "      <td>0</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>63.283519</td>\n",
       "      <td>11.718620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>43.1095</td>\n",
       "      <td>-88.4862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d8aaf92-2430-4b7e-ab0d-0c4f7f000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>59.379769</td>\n",
       "      <td>0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.522222</td>\n",
       "      <td>67.466667</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>48.716667</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>63.283519</td>\n",
       "      <td>11.718620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>43.0696</td>\n",
       "      <td>-89.4239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d8aaf92-2e90-4fc1-8bef-0c4f7f000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.025178</td>\n",
       "      <td>0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.466667</td>\n",
       "      <td>67.833333</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>63.483333</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.283519</td>\n",
       "      <td>11.718620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.500000</td>\n",
       "      <td>43.1095</td>\n",
       "      <td>-88.4862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d8aaf92-37c0-40cf-b40a-0c4f7f000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>47.366448</td>\n",
       "      <td>0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.993549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.736506</td>\n",
       "      <td>51.052010</td>\n",
       "      <td>48.104333</td>\n",
       "      <td>0</td>\n",
       "      <td>58.935234</td>\n",
       "      <td>56.469029</td>\n",
       "      <td>63.283519</td>\n",
       "      <td>11.718620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.500000</td>\n",
       "      <td>41.6018</td>\n",
       "      <td>-87.8899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      10 Mile  10K  15K  5 Mile  5K  Age  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001        0    0    1       0   1   57   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001        0    0    0       0   0   54   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001        0    0    0       0   0   40   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001        0    0    0       0   0   55   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001        0    0    0       0   0   48   \n",
       "\n",
       "                                      Age At Event  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001     50.666667   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001     47.000000   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001     34.000000   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001     48.500000   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001     41.500000   \n",
       "\n",
       "                                      Bangs Lake Multisport Festival  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                               1   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                               0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                               0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                               0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                               2   \n",
       "\n",
       "                                      Big Foot Triathlon  Btn Big 10K  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                   0            0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                   1            0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                   3            0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                   2            0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                   0            0   \n",
       "\n",
       "                                      Bucktown 5K  Cinco De Miler  Concert  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001            0               0        0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001            0               0        0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001            0               0        0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001            0               0        0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001            0               0        0   \n",
       "\n",
       "                                      Days_Out_Registered  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001            30.000000   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001             3.000000   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001            96.333333   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001            12.000000   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001             2.000000   \n",
       "\n",
       "                                      Distance_To_Event(Miles)  Donation  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                 51.964078         0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                 36.025178         0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                 59.379769         0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                 36.025178         0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                 47.366448         0   \n",
       "\n",
       "                                      Fees_Event  Female  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001   61.333333       0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001   89.000000       0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001   99.000000       0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001   94.000000       0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001   99.000000       0   \n",
       "\n",
       "                                      Fleet Feet Sports Soldier Field 10 Mile  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                                        0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                                        0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                                        0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                                        0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                                        0   \n",
       "\n",
       "                                      Fundraising  Fundraising_Goal  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001            0                 0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001            0                 0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001            0                 0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001            0                 0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001            0                 0   \n",
       "\n",
       "                                      Goodie Bag  Half Marathon  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001           0              0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001           0              0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001           0              0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001           0              0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001           0              0   \n",
       "\n",
       "                                      Hot Chocolate  Humboldt Park 5K  Kids  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001              1                 0     0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001              0                 0     0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001              0                 0     0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001              0                 0     0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001              0                 0     0   \n",
       "\n",
       "                                      Kids Race  Male  Mean Temperaturef  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001          0     1          55.500000   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001          0     1          74.000000   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001          0     1          69.666667   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001          0     1          73.500000   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001          0     1          48.993549   \n",
       "\n",
       "                                      Miscellaneous  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001              0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001              0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001              0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001              0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001              0   \n",
       "\n",
       "                                      North Shore Half Marathon  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                          0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                          0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                          0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                          0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                          0   \n",
       "\n",
       "                                      North Shore Turkey Trot  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                        0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                        0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                        0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                        0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                        0   \n",
       "\n",
       "                                      Prev_30D_Mean_Temp  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001           65.916667   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001           67.833333   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001           66.522222   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001           67.466667   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001           51.736506   \n",
       "\n",
       "                                      Previous Year 30D_Mean_Temp  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                    60.250000   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                    51.052010   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                    67.466667   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                    67.833333   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                    51.052010   \n",
       "\n",
       "                                      Previous Year Mean Temperaturef  Raffle  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                        57.000000       0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                        48.104333       0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                        73.500000       0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                        74.000000       0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                        48.104333       0   \n",
       "\n",
       "                                      Registration Day Prev_30D_Mean_Temp  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                            75.616667   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                            65.666667   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                            48.716667   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                            63.483333   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                            58.935234   \n",
       "\n",
       "                                      Registration Day Temperaturef  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                      80.500000   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                      84.000000   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                      48.500000   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                      64.000000   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                      56.469029   \n",
       "\n",
       "                                      Result_Time_Minutes  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001            52.083333   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001            63.283519   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001            63.283519   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001            63.283519   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001            63.283519   \n",
       "\n",
       "                                      Results_Net_Pace_Minutes  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                  8.333333   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                 11.718620   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                 11.718620   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                 11.718620   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                 11.718620   \n",
       "\n",
       "                                      Rock The Night 5K  Season Pass  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                  0            0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                  0            0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                  0            0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                  0            0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                  0            0   \n",
       "\n",
       "                                      South Shore Triathlon  Terrapin  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001                      0         1   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001                      0         0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001                      0         0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001                      0         0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001                      0         0   \n",
       "\n",
       "                                      Tri/Other  Triple Nickel  Valet/Parking  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001          1              0              0   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001          1              0              0   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001          3              0              0   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001          2              0              0   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001          2              0              0   \n",
       "\n",
       "                                      Walk  Walk For Little City         Year  \\\n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001     0                     0  2009.666667   \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001     0                     0  2009.000000   \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001     0                     0  2010.000000   \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001     0                     0  2009.500000   \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001     0                     0  2009.500000   \n",
       "\n",
       "                                      Zip_Coord_Latitude  Zip_Coord_Longitude  \n",
       "4d8aaf92-1770-468a-8c81-0c4f7f000001             41.4706             -87.0783  \n",
       "4d8aaf92-17a0-42f6-9855-0c4f7f000001             43.1095             -88.4862  \n",
       "4d8aaf92-2430-4b7e-ab0d-0c4f7f000001             43.0696             -89.4239  \n",
       "4d8aaf92-2e90-4fc1-8bef-0c4f7f000001             43.1095             -88.4862  \n",
       "4d8aaf92-37c0-40cf-b40a-0c4f7f000001             41.6018             -87.8899  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_columns(gId)\n",
    "gId.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"].dropna() #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),\n",
    "                                              'Female': np.max, 'Male': np.max, '10K': np.max,'15K': np.max, '5 MILE': np.max, '5K': np.max, \n",
    "                                              \"zip_coord_latitude\": np.mean, \"zip_coord_longitude\": np.mean, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\",\"Year\"]].copy(), columns = ['Year',\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").max()\n",
    "\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "#balance data\n",
    "# gId = gId.dropna()\n",
    "# y = gId[gId[dependent_variable.title()] ==1].copy()\n",
    "# n = gId[gId[dependent_variable.title()] ==0].copy().sample(n=(len(y.index)))\n",
    "# yn = pd.concat([y, n], axis=0)\n",
    "# yn.to_csv(fileName)\n",
    "# print(len(yn))\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "# category = None\n",
    "category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"] #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "# df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({dependent_variable: np.max,\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),'Male': np.max,\n",
    "                                              \"distance_qty\": np.mean})\n",
    "#                                               'Female': np.max, , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "# gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Year\"]].copy(), columns = [\"Year\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").max()\n",
    "# gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"].dropna() #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({dependent_variable: np.max,\"Age at Event\": np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),'Male': np.max})#,\n",
    "#                                               'Female': np.max, '10K': np.max,'15K': np.max, '5 MILE': np.max, '5K': np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "# gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\",\"Year\"]].copy(), columns = ['Year',\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").max()\n",
    "\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "# gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.drop(\"TRAINING\", 1)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "#balance data\n",
    "# gId = gId.dropna()\n",
    "# y = gId[gId[dependent_variable.title()] ==1].copy()\n",
    "# n = gId[gId[dependent_variable.title()] ==0].copy().sample(n=(len(y.index)))\n",
    "# yn = pd.concat([y, n], axis=0)\n",
    "# yn.to_csv(fileName)\n",
    "# print(len(yn))\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"].dropna() #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),\n",
    "                                              'Female': np.max, 'Male': np.max, '10K': np.max,'15K': np.max, '5 MILE': np.max, '5K': np.max, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\",\"Year\"]].copy(), columns = ['Year',\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").max()\n",
    "\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "#balance data\n",
    "# gId = gId.dropna()\n",
    "# y = gId[gId[dependent_variable.title()] ==1].copy()\n",
    "# n = gId[gId[dependent_variable.title()] ==0].copy().sample(n=(len(y.index)))\n",
    "# yn = pd.concat([y, n], axis=0)\n",
    "yn.to_csv(fileName)\n",
    "print(len(yn))\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"] #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': lambda x: lastValue(x), 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': lambda x: lastValue(x),'Registration Day Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Mean TemperatureF': lambda x: lastValue(x),'Prev_30d_Mean_Temp': lambda x: lastValue(x), \n",
    "                                              'Previous Year Mean TemperatureF': lambda x: lastValue(x),'Previous Year 30d_Mean_Temp': lambda x: lastValue(x),\n",
    "                                              'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "# , '10K': np.sum,'15K': np.sum, '5 MILE': np.sum, '5K': np.sum\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "# gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "# gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"] #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': np.mean,'Registration Day Prev_30d_Mean_Temp': np.mean, 'Mean TemperatureF': np.mean,\n",
    "                                              'Prev_30d_Mean_Temp': np.mean, 'Previous Year Mean TemperatureF': np.mean,'Previous Year 30d_Mean_Temp': np.mean,\n",
    "                                              'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                              '5 MILE': np.sum, '5K': np.sum, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "# gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 201 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"] #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, \n",
    "                                              'Event Rolling 30d_Mean_Temp/Previous Year': np.mean,'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                              '5 MILE': np.sum, '5K': np.sum, dependent_variable: np.max})\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "# gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gId.to_csv(fileName)\n",
    "expand_columns(gId)\n",
    "gId.head()\n",
    "gId.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gId.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gId2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(gId)\n",
    "gId.head()\n",
    "gId.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#DataFrame to predict all HC\n",
    "\n",
    "year = 2015 \n",
    "# city = c\n",
    "# city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "#         category = \"15K\"\n",
    "#         category = \"5K\"\n",
    "\n",
    "\n",
    "cities = data[(data[\"Event\"]==race) & (data[\"Year\"]==year)][\"event_location\"] #cities with HC in Year\n",
    "regId_city = data[(data[\"event_location\"].isin(cities))][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "# date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\"   + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year)  & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\"  +  str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"Year\"] < year) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df[\"Age at Event\"] = (pd.to_datetime(year, format=\"%Y\") - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "# df[\"Distance_To_Event(miles)\"] = df.apply(lambda x: geopy.distance.distance(GPS_City[city], x['zip_coord']).miles, axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "dependent_variable = race + \" \" + str(year)\n",
    "df[dependent_variable] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day TemperatureF': np.mean,'Registration Day Prev_30d_Mean_Temp': np.mean, 'Mean TemperatureF': np.mean,\n",
    "                                              'Prev_30d_Mean_Temp': np.mean, 'Previous Year Mean TemperatureF': np.mean,'Previous Year 30d_Mean_Temp': np.mean,\n",
    "                                              'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                              '5 MILE': np.sum, '5K': np.sum, dependent_variable: np.max})\n",
    "#'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, 'Event Rolling 30d_Mean_Temp/Previous Year': np.mean\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "# gId2 = gId23[[\"KIDS\",\"HOT CHOCOLATE\"]].copy()\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "gId = gId.rename(columns = {'Year':'Year of Last Event'})\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "gId = change_column_order(gId, dependent_variable, len(gId.columns))\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(fileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DataFrame to registrant ID\n",
    "date = pd.to_datetime('3/11/2016') #date recieved files\n",
    "df = data[(data[\"event_date\"] < date)].copy().sort_values(by=\"event_date\")\n",
    "# df = data.copy().sort_values(by=\"event_date\")\n",
    "print(data[\"Registrant ID\"].nunique())\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max,\"Age\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, \n",
    "                                              'Event Rolling 30d_Mean_Temp/Previous Year': np.mean,'Female': np.max, 'Male': np.max})\n",
    "\n",
    "gId2 = pd.get_dummies(data.copy()[[\"Registrant ID\",\"Registration Category\",\"Category\",\"Kids\",\"Event\"]], columns = [\"Category\",\"Kids\",\"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "gId2['5 MILE'] = np.where(gId2['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,gId2['5 MILE']) \n",
    "gId2['5K'] = np.where(gId2['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,gId2['5K'])\n",
    "gId2 = gId2.groupby(\"Registrant ID\").sum()\n",
    "gId2 = gId2.drop(\"TRAINING\",1)\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId = pd.DataFrame(gId)\n",
    "gId = gId.rename(columns = {'Year':'Year of Last Event',\"Age at Event\":\"Age at Last Event\" })\n",
    "gId = gId.reindex_axis(sorted(gId.columns, key=str.lower), axis=1)\n",
    "\n",
    "gId.columns = map(str.title, gId.columns)\n",
    "\n",
    "# zscore = lambda x: (x - x.mean()) / x.std()\n",
    "# g = gId[:-1].apply(zscore)\n",
    "print(len(gId))\n",
    "gId.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\Ram_Registrants.csv\")\n",
    "#fill na with mean\n",
    "gId= gId.fillna(gId.mean())\n",
    "gId.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\Ram_RegistrantsMean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\Ram_Registrants.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d[\"Unnamed: 0\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gId.columns.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gId.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.columns\n",
    "# data[['Original Registrant ID','Registrant ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gId2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"index\",1)\n",
    "df = df.drop([\"Mean TemperatureF_y\",\"Prev_30d_Mean_Temp_y\",\"Previous Year Mean TemperatureF_y\",\"Previous Year 30d_Mean_Temp_y\"],1)\n",
    "# dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "\n",
    "#fill na with mean\n",
    "# df = df.fillna(df.mean())\n",
    "# df[\"Dependent Variable\"] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df.to_csv(fileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "describe2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expand_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#DF to predict 2015 Chicago Hot Chocolate \n",
    "year = 2015 \n",
    "city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "\n",
    "regId_city = data[(data[\"event_location\"]==city)][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "relevantList = ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE','WALK', 'TRIPLE NICKEL', 'KIDS RACE', '10 MILE'] \n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\" + city + \"_\" + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"event_date\"] < date) &(data[\"Registrant ID\"].isin(regId_city))].copy() \n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "\n",
    "# #grouped data\n",
    "# g = df[[\"Registration Category\",\"Registrant ID\",\"Category\",\"Event\",\"Kids\"]].copy()  \n",
    "# #dummy variable creation\n",
    "# #get dummies will remove original, so create a copy first\n",
    "# g = pd.get_dummies(g, columns=[\"Category\",\"Event\",\"Kids\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "# #add 5 mile and 5k to triple nickel \n",
    "# if \"TRIPLE NICKEL\" in g.columns:\n",
    "#     g['5 MILE'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5 MILE']) \n",
    "#     g['5K'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5K']) \n",
    "# g = g.drop(\"Registration Category\", axis=1)\n",
    "# g = g.groupby(\"Registrant ID\", as_index=False).sum() #group and sum\n",
    "\n",
    "\n",
    "\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df = df[df[\"Category\"].isin(relevantList)] ######### retrieve relevant race data\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df = df.sort_values(by=\"event_date\").drop_duplicates(subset=\"Registrant ID\", keep=\"last\") ########### keep last race\n",
    "# df = pd.merge(df, g, how='left',on=\"Registrant ID\") \n",
    "# df['event_date_y'] = date\n",
    "\n",
    "# df = pd.merge(df, df_y, how='left',on=\"event_date_y\")\n",
    "# df[\"last_event_days_back\"] = (df[\"event_date_y\"] - df[\"event_date\"])/ np.timedelta64(1, 'D') \n",
    "# #replace distance to event with distance to event y\n",
    "# df = df.drop([\"Distance_To_Event(miles)\"],1)\n",
    "# df['city_coord_y'] = df['event_location_y'].map(GPS_City)\n",
    "# df[\"Distance_To_Event(miles)_y\"] = df.apply(lambda x: geopy.distance.distance(x['city_coord_y'], x['zip_coord']).miles, axis=1)\n",
    "\n",
    "\n",
    "# df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1) \n",
    "# df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "# df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\"],1)\n",
    "\n",
    "# df = df.drop(\"index\",1)\n",
    "# df = df.drop([\"Mean TemperatureF_y\",\"Prev_30d_Mean_Temp_y\",\"Previous Year Mean TemperatureF_y\",\"Previous Year 30d_Mean_Temp_y\"],1)\n",
    "# # dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "\n",
    "# #fill na with mean\n",
    "# # df = df.fillna(df.mean())\n",
    "# #groupby\n",
    "# #  f = lambda x: x.fillna(x.mean())\n",
    "# # ransformed = grouped.transform(f)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "# # df[\"Dependent Variable\"] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df.to_csv(fileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#DF to predict 2015 Chicago Hot Chocolate \n",
    "year = 2015 \n",
    "city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "\n",
    "\n",
    "regId_city = data[(data[\"event_location\"]==city)][\"Registrant ID\"] #registration IDs that have been to an event in city\n",
    "\n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\" + race + \"_\" + city + \"_\" + str(year) + \".csv\"\n",
    "else: \n",
    "    dv_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"] \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "# # df_y includes event info, use known weather  # for future we can use average of event or some other predicted weather\n",
    "# df_y = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "# df_y.columns = [str(col) + '_y' for col in df_y.columns] #add suffix for weather of event being predicted\n",
    "\n",
    "#df of previous registrants that attended event in city\n",
    "df = data[(data[\"event_date\"] < date) &(data[\"Registrant ID\"].isin(regId_city))].copy().sort_values(by=\"event_date\")\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df = df.rename(columns = {'Year':'Year of Last Event'}\n",
    "df[\"Age at Event\"] = (pd.to_datetime(date) - df[\"Registrant Birthdate\"]).astype('<m8[Y]')\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Category\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "df['5 MILE'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5 MILE']) \n",
    "df['5K'] = np.where(df['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,df['5K'])\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "gId = df.copy().groupby(\"Registrant ID\").agg({\"Age at Event\": np.max, 'Year': np.max,'fees_event': np.mean, 'fundraising': np.mean, 'fundraising_goal': np.mean,\n",
    "                                              'days_out_registered': np.mean,'results_net_pace_Minutes': np.mean, 'Distance_To_Event(miles)': np.mean, \n",
    "                                              'Registration Day/30d Temperature': np.mean,'Event Mean Temperature/Previous Year': np.mean, \n",
    "                                              'Event Rolling 30d_Mean_Temp/Previous Year': np.mean,'Female': np.max, 'Male': np.max, '10K': np.sum,'15K': np.sum, \n",
    "                                              '5 MILE': np.sum, '5K': np.sum})\n",
    "\n",
    "gId2 = pd.get_dummies(df[[\"Registrant ID\",\"Kids\",\"Event\"]].copy(), columns = [\"Kids\", \"Event\"],dummy_na=False, prefix=\"\",prefix_sep=\"\").groupby(\"Registrant ID\").sum()\n",
    "\n",
    "gId = pd.concat([gId, gId2], axis=1)\n",
    "gId[\"Dependent Variable\"] = np.where(gId[\"Registrant ID\"].isin(dv_list), 1,0)               \n",
    "#                                        , 'CONCERT': np.sum, 'DONATION': np.sum, 'HALF MARATHON': np.sum,'KIDS RACE': np.sum, \n",
    "#                                        'RAFFLE': np.sum, 'SEASON PASS': np.sum, 'TRAINING': np.sum, 'TRI/OTHER': np.sum, 'VALET/PARKING': np.sum, \n",
    "#                                        'WALK': np.sum,'BANGS LAKE MULTISPORT FESTIVAL': np.sum, 'BIG FOOT TRIATHLON': np.sum, 'BUCKTOWN 5K': np.sum,\n",
    "#                                        'CINCO DE MILER': np.sum, 'HOT CHOCOLATE': np.sum, 'HUMBOLDT PARK 5K': np.sum, 'MISCELLANEOUS': np.sum,\n",
    "#                                        'NORTH SHORE HALF MARATHON': np.sum, 'NORTH SHORE TURKEY TROT': np.sum, 'ROCK THE NIGHT 5K': np.sum, \n",
    "#                                        'SOUTH SHORE TRIATHLON': np.sum, 'TERRAPIN': np.sum, 'TRAINING': np.sum, 'WALK FOR LITTLE CITY': np.sum, 'KIDS': np.sum})\n",
    "\n",
    "# relevantList = ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE','WALK', 'TRIPLE NICKEL', 'KIDS RACE', '10 MILE'] \n",
    "\n",
    "# 'Registration Day TemperatureF', 'Registration Day Prev_30d_Mean_Temp',\n",
    "#        'Mean TemperatureF', 'Prev_30d_Mean_Temp',\n",
    "#        'Previous Year Mean TemperatureF', 'Previous Year 30d_Mean_Temp',\n",
    "#        'Registration Day/30d Temperature',\n",
    "#        'Event Mean Temperature/Previous Year',\n",
    "#        'Event Rolling 30d_Mean_Temp/Previous Year', 'Female', 'Male', '10K',\n",
    "#        '15K', '5 MILE', '5K', 'CONCERT', 'DONATION', 'HALF MARATHON',\n",
    "#        'KIDS RACE', 'RAFFLE', 'SEASON PASS', 'TRAINING', 'TRI/OTHER',\n",
    "#        'TRIPLE NICKEL', 'VALET/PARKING', 'WALK',\n",
    "#        'BANGS LAKE MULTISPORT FESTIVAL', 'BIG FOOT TRIATHLON', 'BUCKTOWN 5K',\n",
    "#        'CINCO DE MILER', 'HOT CHOCOLATE', 'HUMBOLDT PARK 5K', 'MISCELLANEOUS',\n",
    "#        'NORTH SHORE HALF MARATHON', 'NORTH SHORE TURKEY TROT',\n",
    "#        'ROCK THE NIGHT 5K', 'SOUTH SHORE TRIATHLON', 'TERRAPIN', 'TRAINING',\n",
    "#        'WALK FOR LITTLE CITY', 'KIDS'\n",
    "\n",
    "# #grouped data\n",
    "# g = df[[\"Registration Category\",\"Registrant ID\",\"Category\",\"Event\",\"Kids\"]].copy()  \n",
    "# #dummy variable creation\n",
    "# #get dummies will remove original, so create a copy first\n",
    "# g = pd.get_dummies(g, columns=[\"Category\",\"Event\",\"Kids\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "# #add 5 mile and 5k to triple nickel \n",
    "# if \"TRIPLE NICKEL\" in g.columns:\n",
    "#     g['5 MILE'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5 MILE']) \n",
    "#     g['5K'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5K']) \n",
    "# g = g.drop(\"Registration Category\", axis=1)\n",
    "# g = g.groupby(\"Registrant ID\", as_index=False).sum() #group and sum\n",
    "\n",
    "\n",
    "\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df = df[df[\"Category\"].isin(relevantList)] ######### retrieve relevant race data\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df = df.sort_values(by=\"event_date\").drop_duplicates(subset=\"Registrant ID\", keep=\"last\") ########### keep last race\n",
    "# df = pd.merge(df, g, how='left',on=\"Registrant ID\") \n",
    "# df['event_date_y'] = date\n",
    "\n",
    "# df = pd.merge(df, df_y, how='left',on=\"event_date_y\")\n",
    "# df[\"last_event_days_back\"] = (df[\"event_date_y\"] - df[\"event_date\"])/ np.timedelta64(1, 'D') \n",
    "# #replace distance to event with distance to event y\n",
    "# df = df.drop([\"Distance_To_Event(miles)\"],1)\n",
    "# df['city_coord_y'] = df['event_location_y'].map(GPS_City)\n",
    "# df[\"Distance_To_Event(miles)_y\"] = df.apply(lambda x: geopy.distance.distance(x['city_coord_y'], x['zip_coord']).miles, axis=1)\n",
    "\n",
    "\n",
    "# df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1) \n",
    "# df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "# df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\"],1)\n",
    "\n",
    "# df = df.drop(\"index\",1)\n",
    "# df = df.drop([\"Mean TemperatureF_y\",\"Prev_30d_Mean_Temp_y\",\"Previous Year Mean TemperatureF_y\",\"Previous Year 30d_Mean_Temp_y\"],1)\n",
    "# # dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "\n",
    "# #fill na with mean\n",
    "# # df = df.fillna(df.mean())\n",
    "# #groupby\n",
    "# #  f = lambda x: x.fillna(x.mean())\n",
    "# # ransformed = grouped.transform(f)\n",
    "\n",
    "# df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "# df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "# df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\",'distance_unit'],1)\n",
    "\n",
    "# df[\"Dependent Variable\"] = np.where(df[\"Registrant ID\"].isin(dv_list), 1,0)\n",
    "# print(df[\"Registrant ID\"].nunique())\n",
    "# df.to_csv(fileName, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.isnull().any()\n",
    "df[df[\"Registrant ID\"].isnull()]#.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#DF to predict 2015 Chicago Hot Chocolate \n",
    "year = 2015 \n",
    "city = \"Chicago, IL\" \n",
    "race = \"HOT CHOCOLATE\" \n",
    "category = None\n",
    "\n",
    "\n",
    "relevantList = ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE','WALK', 'TRIPLE NICKEL', 'KIDS RACE', '10 MILE'] \n",
    "# filter out from ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE',\n",
    "#        'TRAINING', 'DONATION', 'VALET/PARKING', 'WALK', 'RAFFLE',\n",
    "#        'GOODIE BAG', 'CONCERT', 'TRIPLE NICKEL', 'SEASON PASS',\n",
    "#        'KIDS RACE', '10 MILE']\n",
    "date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique() [0]\n",
    "if category == None: \n",
    "    id_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"].to_dict() \n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/test/\" + race + \"_\" + city + \"_\" + str(year) + \".csv\"\n",
    "else: \n",
    "    id_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"].to_dict()\n",
    "    fileName = \"C:/Users/patrick.carey/Desktop/RamRacing/test/\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "\n",
    "df = data[data[\"event_date\"] < date].copy() \n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.drop(\"Count\", 1)\n",
    "df = pd.merge(df,weather, how=\"left\") #add weather for x\n",
    "g = df[[\"Registrant ID\", 'Registration Category',\"Category\",\"Event\",\"Kids\"]].copy() #df for later grouped data \n",
    "\n",
    "#dummy variable creation\n",
    "#get dummies will remove original, so create a copy first\n",
    "g[\"Event_\"] = g[\"Event\"]\n",
    "g[\"Category_\"] = g[\"Category\"]\n",
    "df[\"Gender\"] = df[\"Registrant Gender\"] \n",
    "df = pd.get_dummies(df, columns=[\"Gender\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "g[\"Kids_\"] = g[\"Kids\"]\n",
    "g = pd.get_dummies(g, columns=[\"Category\",\"Event\",\"Kids\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "#add 5 mile and 5k to triple nickel \n",
    "g['5 MILE'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5 MILE']) \n",
    "g['5K'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5K']) \n",
    "\n",
    "g = g.drop('Registration Category',1) \n",
    "g = g.groupby(\"Registrant ID\", as_index=False).sum() #group and sum\n",
    "w = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date)].copy() #weather for event\n",
    "w.columns = [str(col) + '_y' for col in w.columns] #add suffix for weather ofevent being predicted\n",
    "\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df[df[\"Category\"].isin(relevantList)] ######### retrieve relevant race data\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df = df.sort_values(by=\"event_date\").drop_duplicates(subset=\"Registrant ID\", keep=\"last\") ########### keep last race\n",
    "df = pd.merge(df, g, how='left',on=\"Registrant ID\") \n",
    "df['event_date_y'] = date\n",
    "df = pd.merge(df, w, how='left',on=\"event_date_y\")\n",
    "df[\"last_event_days_back\"] = (df[\"event_date_y\"] - df[\"event_date\"])/ np.timedelta64(1, 'D') \n",
    "\n",
    "# dependent_variable = race + \" \" + str(year) + \" \" + city\n",
    "df[\"Dependent Variable\"] = np.where(df[\"Registrant ID\"].isin(id_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1) \n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1) \n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\"],1)\n",
    "# df = df.drop([\"Mean TemperatureF_y\",\"Prev_30d_Mean_Temp_y\",\"Previous Year Mean TemperatureF_y\",\"Previous Year 30d_Mean_Temp_y\"],1)\n",
    "print(df[\"Registrant ID\"].nunique())\n",
    "df.to_csv(fileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"Registrant ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######create new df for queries\n",
    "####drop NA for necessary columns #######\n",
    "df =data.copy().dropna(subset=[\"User ID\",\"Registrant Birthdate\",\"Registrant ID\", \"Registrant Gender\",\"Age\",\"Age at Event\"])\n",
    "df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "#set new index\n",
    "df = df.sort_values(by=['Year','Category', 'Event','event_location']) #sort for faster indexing\n",
    "df[\"event_date\"] = df[\"event_date\"].dt.date #drop time piece\n",
    "df.set_index(['Category', 'Event'], inplace=True)\n",
    "df[df['Year']>2016].index.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "df = data.copy()\n",
    "r = len(df[\"Category\"].unique())\n",
    "cs = []\n",
    "for i in range(r-1):\n",
    "    temp = tuple(itertools.combinations(df[\"Category\"].unique(), i))\n",
    "    for z in temp:\n",
    "        cs.append(z)\n",
    "\n",
    "print(len(cs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expand_columns(g)\n",
    "# g.head()\n",
    "\n",
    "# expand_columns(w)\n",
    "# w.head()\n",
    "\n",
    "expand_columns(df)\n",
    "df.describe(include=\"all\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(df)\n",
    "df[(df[\"Event\"] == race)  & (df[\"event_location\"]==city) & (df[\"Dependent Variable\"]==1)].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dummy variable creation\n",
    "#get dummies will remove original, so create a copy first\n",
    "data[\"Event_\"] = data[\"Event\"]\n",
    "data[\"Category_\"] = data[\"Category\"]\n",
    "data[\"Gender\"] = data[\"Registrant Gender\"]\n",
    "data[\"Kids_\"] = data[\"Kids\"]\n",
    "# data[\"Registration Event Name_\"] = data[\"Registration Event Name\"]\n",
    "data = pd.get_dummies(data, columns=[\"Gender\",\"Category_\",\"Event_\",\"Kids_\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "\n",
    "#add 5 mile and 5k to triple nickel\n",
    "data['5 MILE'] = np.where(data['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,data['5 MILE'])\n",
    "data['5K'] = np.where(data['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,data['5K'])\n",
    "\n",
    "#event date dummies\n",
    "# data['event_location_'] = data['event_location']\n",
    "# data = pd.get_dummies(data, columns=['event_location_'],dummy_na=False, prefix=\"\",prefix_sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "data.head()\n",
    "# data[data[\"Category\"] ==\"GOODIE BAG\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create column for dependent variable, 2015 race attendence\n",
    "dependent = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Retrieve locations\n",
    "import pickle\n",
    "import geopy\n",
    "import geopy.distance\n",
    "\n",
    "with open('GPS_Ram.pickle', 'rb') as handle: \n",
    "    GPS_Ram = pickle.load(handle) #load saved dict\n",
    "# GPS_Ram = {} #only for creating new dict\n",
    "\n",
    "geolocator = geopy.Nominatim()\n",
    "for index, row in data.iterrows():\n",
    "    eventCity = [index,row['event_location']][1]\n",
    "    registrantZip = [index,row['Registrant Zipcode']][1]\n",
    "    \n",
    "    if eventCity == None:\n",
    "        continue\n",
    "    elif eventCity in GPS_Ram.keys():\n",
    "        eventCityGPS = GPS_Ram[eventCity]\n",
    "    else:\n",
    "        try:\n",
    "            eventCityRequest = geolocator.geocode(eventCity, timeout=10)\n",
    "            eventCityGPS = (eventCityRequest.latitude, eventCityRequest.longitude)\n",
    "            GPS_Ram[eventCity] = eventCityGPS\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    if registrantZip == None:\n",
    "        continue\n",
    "    elif registrantZip in GPS_Ram.keys():\n",
    "        registrantZipGPS = GPS_Ram[registrantZip]\n",
    "    else:\n",
    "        try:\n",
    "            registrantZipRequest = geolocator.geocode(registrantZip, timeout=10)\n",
    "            registrantZipGPS = (registrantZipRequest.latitude, registrantZipRequest.longitude)\n",
    "            GPS_Ram[registrantZip] = registrantZipGPS\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    data.loc[index,\"Distance_To_Event\"] = geopy.distance.distance(eventCityGPS, registrantZipGPS).miles\n",
    "        \n",
    "\n",
    "with open('GPS_Ram.pickle', 'wb') as handle:\n",
    "    pickle.dump(GPS_Ram, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######create new df for queries\n",
    "####drop NA for necessary columns #######\n",
    "df =data.copy().dropna(subset=[\"User ID\",\"Registrant Birthdate\",\"Registrant ID\", \"Registrant Gender\",\"Age\",\"Age at Event\"])\n",
    "#set new index\n",
    "df = df.sort_values(by=['Year','Category', 'Event','event_location']) #sort for faster indexing\n",
    "df[\"event_date\"] = df[\"event_date\"].dt.date #drop time piece\n",
    "df.set_index(['Year','Category', 'Event','event_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split into pre and post 2015\n",
    "df.loc[\"2015\"].head()\n",
    "df.loc[\"Year\" < 2015].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df.loc[\"15K\", \"HOT CHOCOLATE\",\"Chicago, IL\"].copy()\n",
    "x = x.groupby('Registrant ID',as_index=False).sum()\n",
    "x.to_csv(r\"x.csv\")\n",
    "# x[\"Mean Temperature\"] = x[\"event_date\"].map(weatherDict['Chicago'][\"event_date\"][\"Mean TemperatureF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = df.loc[\"15K\",\"HOT CHOCOLATE\",\"Chicago, IL\",\"2009\":\"2015\"]\n",
    "d.to_csv(r\"C:\\Users\\patrick.carey\\Desktop\\RamRacing\\x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expand_columns(df)\n",
    "# df.loc[('15K','HOT CHOCOLATE'):(\"GOODIE BAG\",\"HOT CHOCOLATE\")].head() #[len(\"User ID\") > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####drop NA for necessary columns #######\n",
    "data =data.copy().dropna(subset=[\"User ID\",\"Registrant Birthdate\",\"Registrant ID\", \"Registrant Gender\",\"Age\",\"Age at Event\"])\n",
    "# describe2(data)\n",
    "\n",
    "#####drop duplicate registrant entries #####\n",
    "# data = data.drop_duplicates() # 921791 - 921776 = 15\n",
    "# data = data.drop_duplicates(subset=[\"Registrant ID\", \"Registration Event Name\",\"Registration Category\",\"event_date\"]) #duplicated regisrations by different Users,etc.\n",
    "# describe2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.event_location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weatherDict[\"Chicago\"][[0,2]].head()\n",
    "weatherDict[\"Chicago\"].insert(0, \"Location\", \"Chicago, IL\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DF to predict 2015 Chicago Hot Chocolate\n",
    "year = 2015\n",
    "city = \"Chicago, IL\"\n",
    "race = \"HOT CHOCOLATE\"\n",
    "category = \"15K\"\n",
    "\n",
    "\n",
    "relevantList = ['15K', '5K', 'TRI/OTHER', 'HALF MARATHON', '10K', '5 MILE','WALK', 'TRIPLE NICKEL', 'KIDS RACE', '10 MILE'] #filter out goodie bags, concerts, etc.\n",
    "\n",
    "date = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"event_date\"].unique()\n",
    "if category == None:\n",
    "    id_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city)][\"Registrant ID\"]\n",
    "    fileName = \"C:\\\\Users\\\\patrick.carey\\\\Desktop\\\\RamRacing\\\\\" + race + \"_\" + city + \"_\" + str(year) +\".csv\"\n",
    "else:\n",
    "    id_list = data[(data[\"Event\"] == race) & (data[\"Year\"] == year) & (data[\"event_location\"]==city) & (data[\"Category\"]==category)][\"Registrant ID\"]\n",
    "    fileName = \"C:\\\\Users\\\\patrick.carey\\\\Desktop\\\\RamRacing\\\\\"+race + \"_\" + city + \"_\" + str(year) + \"_\" + category +\".csv\"\n",
    "\n",
    "df = data[data[\"event_date\"] < date[0]].copy()\n",
    "df = df.drop(\"Count\", 1)\n",
    "\n",
    "g = df[[\"Registrant ID\", 'Registration Category',\"Category\",\"Event\",\"Kids\"]].copy()\n",
    "#dummy variable creation\n",
    "#get dummies will remove original, so create a copy first\n",
    "# g[\"Event_\"] = g[\"Event\"]\n",
    "# g[\"Category_\"] = g[\"Category\"]\n",
    "df[\"Gender\"] = df[\"Registrant Gender\"]\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "# g[\"Kids_\"] = g[\"Kids\"]\n",
    "# data[\"Registration Event Name_\"] = data[\"Registration Event Name\"]\n",
    "g = pd.get_dummies(g, columns=[\"Category\",\"Event\",\"Kids\"],dummy_na=False, prefix=\"\",prefix_sep=\"\")\n",
    "#add 5 mile and 5k to triple nickel\n",
    "g['5 MILE'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5 MILE'])\n",
    "g['5K'] = np.where(g['Registration Category'].str.contains(\"TRIPLE NICKEL\"), 1,g['5K'])\n",
    "g = g.drop('Registration Category',1)\n",
    "g = g.groupby(\"Registrant ID\", as_index=False).sum()\n",
    "w = weather[(weather[\"event_location\"] == city) & (weather[\"event_date\"] == date[0])].copy()\n",
    "\n",
    "df = df[df[\"Category\"].isin(relevantList)]\n",
    "df = df.sort_values(by=\"event_date\").drop_duplicates(subset=\"Registrant ID\", keep=\"last\")\n",
    "df = pd.merge(df, g, on=\"Registrant ID\")\n",
    "df = pd.merge(df, w, on=\"event_location\")\n",
    "\n",
    "df[\"last_event_days_back\"] = (df[\"event_date_y\"] - df[\"event_date_x\"])/1\n",
    "df[\"Dependent Variable\"] = np.where(df[\"Registrant ID\"].isin(id_list), 1,0)\n",
    "\n",
    "df = df.drop([\"User Email\",\"User First Name\",\"User Last Name\",\"Registrant Email\",\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Gender\",\"Registrant Birthdate\"],1)\n",
    "df = df.drop([\"fees_first\",\"fees_first_until\",\"fees_second\",\"fees_second_until\",\"fees_third\",\"fees_third_until\",\"fees_fourth\",\"fees_fourth_until\"],1)\n",
    "df = df.drop([\"Age\",\"Registrant Zipcode\",\"distance_qty\"],1)\n",
    "\n",
    "df.to_csv(fileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.loc[\"Chicago, IL\"][\"Mean TemperatureF\"] = df.loc['Chicago, IL'][\"event_date\"].map(ChicagoWeather[\"Mean TemperatureF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training before 2015, testing = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data[(data[\"event_date\"].isin([pd.Timestamp(\"2014-11-09\"),pd.Timestamp(\"2015-11-08\")])) & (data[\"Event\"]==\"HOT CHOCOLATE\")&(data[\"Category\"]==\"15K\")& ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.to_datetime(\"2014-11-09\") \n",
    "x.desribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = data.groupby('Registrant ID',as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand_columns(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "# data.plot(kind='scatter', x='Age', y='Count', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter',  x='Age', y='Category_15K', ax=axs[1])\n",
    "# data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Load the diabetes dataset\n",
    "# diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.15K[:-20]\n",
    "diabetes_y_test = diabetes.15K[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"Week of increase fee\"] = np.where((pd.to_datetime(data[\"Registration Date\"]) - pd.to_datetime(data['fees_first_until'])) < np.timedelta64(7, 'D'),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ID_Dict = data[[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\",\"Registrant ID\"]]\n",
    "# # ID_Dict = {tuple(x[:3]):x[3] for x in ID_Dict.values}\n",
    "\n",
    "# data[\"TempID\"] = zip(data[[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\"]])\n",
    "# ID_Dict = data.set_index(\"TempID\")[\"Registrant ID\"].to_dict()\n",
    "# data[\"TempID2\"] = data[\"TempID\"].map(ID_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[data.duplicated(subset=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\"], keep=False) ].sort_values(by=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[data.duplicated(subset=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\",\"Registrant ID\", \"Registrant Gender\"], keep=False)].sort_values(by=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expand_columns(data) #same registrant at events\n",
    "data[data.duplicated(subset=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\",\"Registration Event Name\"], keep=False)].sort_values(by=[\"Registrant First Name\",\"Registrant Last Name\",\"Registrant Birthdate\"]).to_csv(\"duplicated_event.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data[\"User ID\"]==\"524467a0-2728-44e6-aefb-5ba3c0a86524\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',len(data.columns))\n",
    "# data[data['Registration Category']==\"1.5 MILE FAMILY WALK\"].head()\n",
    "# data[\"results_net_pace_Minutes\"].head()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#fill in blank registrant ID with User ID\n",
    "#data[data[\"Registrant ID\"].isnull() & (data[\"User First Name\"] != data[\"Registrant First Name\"]) & data[\"Registrant First Name\"].notnull()].sort_values(by=\"User ID\")\n",
    "data[\"Registrant ID\"] = data[\"Registrant ID\"].fillna(\"FILL_NULL_w_USER_ID:\"+data[\"User ID\"])\n",
    "\n",
    "#removed duplicated registrant event date rows, example is 2 identical entries but one does not have results_net_pace\n",
    "    # also back in 2009 database was new and some errors in entries caused duplication, so the legend goes\n",
    "data = data.sort_values(by=\"results_net_pace\", na_position=\"last\").drop_duplicates(subset=[\"Registrant ID\",'event_date',\"Registration Event Name\",\"Registration Category\"], keep=\"first\").sort_values(by=\"Registrant ID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',len(data.columns))\n",
    "data[data[\"Event\"] ==\"HOT CHOCOLATE\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = data.drop('Registrant Zipcode', 1) #drop zip due to SAS proc import error\n",
    "data.to_csv(r\"F:\\SAS_VA\\RAM_Transaction_2016_5_12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',len(data.columns))\n",
    "data[data[\"fees_event\"] < 0].head()\n",
    "# data[data[\"fees_event\"] < 0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data[\"Registrant ID\"]==\"4d8aba6a-1f00-41f4-ae07-0c4f7f000001\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
